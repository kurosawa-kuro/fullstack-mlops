name: ML Model CI/CD (DuckDBå¯¾å¿œ)

on:
  push:
    paths:
      - 'src/**'
      - 'configs/**'
      - 'src/ml/data/**'
      - 'src/ml/dwh/**'
      - 'tests/**'
      - 'configs/requirements.txt'
      - '.github/workflows/ml-cicd.yml'
  pull_request:
    paths:
      - 'src/**'
      - 'configs/**'
      - 'src/ml/data/**'
      - 'src/ml/dwh/**'
      - 'tests/**'
      - 'configs/requirements.txt'
      - '.github/workflows/ml-cicd.yml'
  workflow_dispatch:  # æ‰‹å‹•å®Ÿè¡Œå¯èƒ½

env:
  # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
  APP_NAME: "House Price Predictor"
  APP_VERSION: "1.0.0"
  APP_ENVIRONMENT: "ci"
  
  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
  DB_TYPE: "duckdb"
  DB_PATH: "src/ml/data/dwh/data/house_price_dwh.duckdb"
  
  # MLflowè¨­å®šï¼ˆCI/CDç’°å¢ƒã§ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ï¼‰
  MLFLOW_TRACKING_URI: "file:./mlruns"
  MLFLOW_EXPERIMENT_NAME: "house_price_prediction"
  MLFLOW_DISABLE_TRACKING: "false"
  
  # ãƒ­ã‚°è¨­å®š
  LOG_LEVEL: "INFO"
  LOG_FORMAT: "json"
  LOG_FILE: "logs/app.log"
  
  # APIè¨­å®š
  API_HOST: "0.0.0.0"
  API_PORT: "8000"
  API_WORKERS: "4"
  
  # UIè¨­å®š
  UI_HOST: "0.0.0.0"
  UI_PORT: "8501"
  
  # ç›£è¦–è¨­å®š
  MONITORING_ENABLED: "true"
  METRICS_PORT: "9090"
  
  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
  SECRET_KEY: "ci-secret-key-for-testing"
  DEBUG: "false"

jobs:
  # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆDuckDB DWHä½¿ç”¨ï¼‰- å…¨ãƒ–ãƒ©ãƒ³ãƒã§å®Ÿè¡Œ
  train-model:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('configs/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r configs/requirements.txt

      - name: Create necessary directories
        run: |
          mkdir -p src/ml/data/raw
          mkdir -p src/ml/data/dwh/scripts
          mkdir -p src/ml/data/dwh/data
          mkdir -p src/ml/data/dwh/core
          mkdir -p src/ml/data/dwh/config
          mkdir -p src/ml/models/trained
          mkdir -p logs
          mkdir -p mlruns

      - name: Initialize MLflow
        run: |
          # MLflowã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
          export MLFLOW_TRACKING_URI="file:./mlruns"
          export MLFLOW_EXPERIMENT_NAME="house_price_prediction"
          
          # MLflowã®åˆæœŸåŒ–
          python -c "
          import mlflow
          import os
          import sys
          
          try:
              # MLflowã®è¨­å®š
              mlflow.set_tracking_uri('file:./mlruns')
              mlflow.set_experiment('house_price_prediction')
              
              print('âœ… MLflowåˆæœŸåŒ–å®Œäº†')
              print(f'ğŸ“ MLflow tracking URI: {mlflow.get_tracking_uri()}')
              
              # å®Ÿé¨“ã®å­˜åœ¨ç¢ºèª
              experiment = mlflow.get_experiment_by_name('house_price_prediction')
              if experiment:
                  print(f'ğŸ”¬ MLflow experiment ID: {experiment.experiment_id}')
              else:
                  print('âš ï¸  MLflow experiment not found, creating new one')
                  mlflow.create_experiment('house_price_prediction')
                  
          except Exception as e:
              print(f'âš ï¸  MLflowåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}')
              print('ğŸ“ MLflowãªã—ã§ç¶šè¡Œã—ã¾ã™')
              # MLflowã‚’ç„¡åŠ¹åŒ–
              os.environ['MLFLOW_DISABLE_TRACKING'] = 'true'
          "

      - name: Create sample data
        run: |
          # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
          python -c "
          import pandas as pd
          import os
          
          # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
          sample_data = pd.DataFrame({
              'sqft': [1500, 2000, 1200, 1800, 2200, 1600, 2400, 1400, 1900, 2100],
              'bedrooms': [3, 4, 2, 3, 4, 3, 5, 2, 3, 4],
              'bathrooms': [2, 3, 1, 2, 3, 2, 4, 1, 2, 3],
              'year_built': [2010, 2015, 2008, 2012, 2018, 2011, 2020, 2009, 2013, 2017],
              'location': ['Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Suburban', 'Urban', 'Rural', 'Suburban', 'Urban'],
              'condition': ['Good', 'Excellent', 'Fair', 'Good', 'Excellent', 'Good', 'Excellent', 'Fair', 'Good', 'Excellent'],
              'price': [300000, 450000, 200000, 350000, 500000, 320000, 550000, 180000, 380000, 480000]
          })
          
          # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
          os.makedirs('src/ml/data/raw', exist_ok=True)
          sample_data.to_csv('src/ml/data/raw/house_data.csv', index=False)
          print('âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸ')
          "

      - name: Build DuckDB DWH
        run: |
          # DWHã‚¹ã‚­ãƒ¼ãƒã‚’åˆæœŸåŒ–ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
          python -c "
          import sys
          sys.path.insert(0, 'src')
          import duckdb
          import pandas as pd
          
          # DuckDBã«æ¥ç¶š
          conn = duckdb.connect('src/ml/data/dwh/data/house_price_dwh.duckdb')
          
          # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
          sample_data = pd.DataFrame({
              'id': range(1, 11),
              'sqft': [1500, 2000, 1200, 1800, 2200, 1600, 2400, 1400, 1900, 2100],
              'bedrooms': [3, 4, 2, 3, 4, 3, 5, 2, 3, 4],
              'bathrooms': [2, 3, 1, 2, 3, 2, 4, 1, 2, 3],
              'year_built': [2010, 2015, 2008, 2012, 2018, 2011, 2020, 2009, 2013, 2017],
              'location': ['Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Suburban', 'Urban', 'Rural', 'Suburban', 'Urban'],
              'condition': ['Good', 'Excellent', 'Fair', 'Good', 'Excellent', 'Good', 'Excellent', 'Fair', 'Good', 'Excellent'],
              'price': [300000, 450000, 200000, 350000, 500000, 320000, 550000, 180000, 380000, 480000]
          })
          
          # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦ä¿å­˜
          conn.execute('DROP TABLE IF EXISTS bronze_raw_house_data')
          conn.execute('CREATE TABLE bronze_raw_house_data AS SELECT * FROM sample_data')
          
          # ã‚·ãƒ³ãƒ—ãƒ«ãªv_house_analyticsãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆ
          conn.execute('''
            CREATE OR REPLACE VIEW v_house_analytics AS
            SELECT 
              id as transaction_id,
              price,
              sqft,
              bedrooms,
              bathrooms,
              (price / sqft) as price_per_sqft,
              (2025 - year_built) as house_age,
              (bedrooms / bathrooms) as bed_bath_ratio,
              location as location_name,
              CASE 
                WHEN location ILIKE '%suburban%' THEN 'Suburban'
                WHEN location ILIKE '%urban%' THEN 'Urban'
                ELSE 'Rural'
              END as location_type,
              condition as condition_name,
              CASE 
                WHEN condition = 'Excellent' THEN 5
                WHEN condition = 'Good' THEN 4
                WHEN condition = 'Fair' THEN 3
                WHEN condition = 'Poor' THEN 2
                ELSE 1
              END as condition_score,
              year_built as year_value,
              CONCAT((year_built // 10) * 10, 's') as decade,
              CONCAT((year_built // 100) + 1, 'th Century') as century,
              CURRENT_DATE as transaction_date
            FROM bronze_raw_house_data
          ''')
          
          print('âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªv_house_analyticsãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¾ã—ãŸ')
          conn.close()
          "
          
          # DuckDB DWHã‚’æ§‹ç¯‰
          python src/ml/data/dwh/scripts/setup_dwh.py \
            --csv-file src/ml/data/raw/house_data.csv \
            --db-path src/ml/data/dwh/data/house_price_dwh.duckdb
          
          # DWHã®çŠ¶æ…‹ç¢ºèª
          python src/ml/data/dwh/scripts/setup_dwh.py \
            --db-path src/ml/data/dwh/data/house_price_dwh.duckdb \
            --validate-only

      - name: Run DuckDB-based ML pipeline
        run: |
          python src/ml/models/train_model.py \
            --config src/configs/model_config.yaml \
            --duckdb-path src/ml/data/dwh/data/house_price_dwh.duckdb \
            --models-dir src/ml/models \
            --view-name v_house_analytics

      - name: Verify model artifacts
        run: |
          ls -la src/ml/models/trained/
          python -c "
          import joblib
          model = joblib.load('src/ml/models/trained/house_price_prediction.pkl')
          preprocessor = joblib.load('src/ml/models/trained/house_price_prediction_encoders.pkl')
          print('âœ… ãƒ¢ãƒ‡ãƒ«ã¨å‰å‡¦ç†å™¨ã®èª­ã¿è¾¼ã¿æˆåŠŸ')
          "

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-models-${{ github.sha }}
          path: |
            src/ml/models/trained/house_price_prediction.pkl
            src/ml/models/trained/house_price_prediction_encoders.pkl
          retention-days: 30

      - name: Upload DuckDB database
        uses: actions/upload-artifact@v4
        with:
          name: duckdb-dwh-${{ github.sha }}
          path: src/ml/data/dwh/data/house_price_dwh.duckdb
          retention-days: 30

      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-artifacts-${{ github.sha }}
          path: mlruns/
          retention-days: 30

  # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆDuckDB DWHæ§‹ç¯‰å¾Œã®ãƒ†ã‚¹ãƒˆï¼‰
  test:
    runs-on: ubuntu-latest
    needs: train-model
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('configs/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov
          pip install -r configs/requirements.txt

      - name: Create necessary directories
        run: |
          mkdir -p logs
          mkdir -p mlruns

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models-${{ github.sha }}
          path: src/ml/models/trained/

      - name: Download DuckDB database
        uses: actions/download-artifact@v4
        with:
          name: duckdb-dwh-${{ github.sha }}
          path: src/ml/data/dwh/data/

      - name: Download MLflow artifacts
        uses: actions/download-artifact@v4
        with:
          name: mlflow-artifacts-${{ github.sha }}
          path: mlruns/

      - name: Run tests
        run: |
          # src/testsã¨testsã®ä¸¡æ–¹ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
          pytest src/tests/test_ml_pipeline.py -v --cov=src --cov-report=xml --cov-report=html
          pytest tests/unit/test_ml_pipeline.py -v --cov=src --cov-report=xml --cov-report=html

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆï¼ˆDuckDBå¯¾å¿œï¼‰- å…¨ãƒ–ãƒ©ãƒ³ãƒã§å®Ÿè¡Œ
  model-performance:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('configs/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r configs/requirements.txt

      - name: Create necessary directories
        run: |
          mkdir -p logs
          mkdir -p mlruns

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models-${{ github.sha }}
          path: src/ml/models/trained/

      - name: Download DuckDB database
        uses: actions/download-artifact@v4
        with:
          name: duckdb-dwh-${{ github.sha }}
          path: src/ml/data/dwh/data/

      - name: Download MLflow artifacts
        uses: actions/download-artifact@v4
        with:
          name: mlflow-artifacts-${{ github.sha }}
          path: mlruns/

      - name: Run model performance tests
        run: |
          pytest src/tests/test_ml_pipeline.py::TestModelPipeline::test_model_files_exist -v
          pytest src/tests/test_ml_pipeline.py::TestModelPipeline::test_model_can_load -v
          pytest src/tests/test_ml_pipeline.py::TestModelPipeline::test_model_can_predict -v

      - name: Test DuckDB integration
        run: |
          python -c "
          import duckdb
          import joblib
          import pandas as pd
          
          # DuckDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
          conn = duckdb.connect('src/ml/data/dwh/data/house_price_dwh.duckdb')
          data = conn.execute('SELECT * FROM v_house_analytics LIMIT 5').fetchdf()
          conn.close()
          
          # ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
          model = joblib.load('src/ml/models/trained/house_price_prediction.pkl')
          preprocessor = joblib.load('src/ml/models/trained/house_price_prediction_encoders.pkl')
          
          # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ï¼ˆDuckDBãƒ“ãƒ¥ãƒ¼ã®ã‚«ãƒ©ãƒ åã‚’ä½¿ç”¨ï¼‰
          sample = data.iloc[0:1]
          X = pd.DataFrame({
              'sqft': sample['sqft'],
              'bedrooms': sample['bedrooms'],
              'bathrooms': sample['bathrooms'],
              'house_age': sample['house_age'],
              'price_per_sqft': sample['price_per_sqft'],
              'bed_bath_ratio': sample['bed_bath_ratio'],
              'location': sample['location_name'],
              'condition': sample['condition_name']
          })
          
          X_transformed = preprocessor.transform(X)
          prediction = model.predict(X_transformed)
          
          print(f'âœ… DuckDBçµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ')
          print(f'ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬çµæœ: ${prediction[0]:,.2f}')
          "

      - name: Model performance summary
        run: |
          echo "ğŸ¯ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆDuckDBå¯¾å¿œï¼‰"
          echo "ğŸ“Š ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $(ls -lh src/ml/models/trained/house_price_prediction.pkl | awk '{print $5}')"
          echo "ğŸ“Š å‰å‡¦ç†å™¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $(ls -lh src/ml/models/trained/house_price_prediction_encoders.pkl | awk '{print $5}')"
          echo "ğŸ“Š DuckDBãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: $(ls -lh src/ml/data/dwh/data/house_price_dwh.duckdb | awk '{print $5}')"

  # GitHub Releaseä½œæˆï¼ˆã‚¿ã‚°ãƒ—ãƒƒã‚·ãƒ¥æ™‚ã®ã¿ï¼‰
  create-release:
    runs-on: ubuntu-latest
    needs: [train-model, model-performance]
    if: startsWith(github.ref, 'refs/tags/')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: trained-models-${{ github.sha }}
          path: src/ml/models/trained/

      - name: Download DuckDB database
        uses: actions/download-artifact@v4
        with:
          name: duckdb-dwh-${{ github.sha }}
          path: src/ml/data/dwh/data/

      - name: Download MLflow artifacts
        uses: actions/download-artifact@v4
        with:
          name: mlflow-artifacts-${{ github.sha }}
          path: mlruns/

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          files: |
            src/ml/models/trained/house_price_prediction.pkl
            src/ml/models/trained/house_price_prediction_encoders.pkl
            src/ml/data/dwh/data/house_price_dwh.duckdb
            mlruns/
          body: |
            ## ğŸ  House Price Prediction Model Release (DuckDBå¯¾å¿œ)
            
            ### ğŸ“¦ å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
            - `house_price_prediction.pkl`: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
            - `house_price_prediction_encoders.pkl`: å‰å‡¦ç†å™¨
            - `house_price_dwh.duckdb`: DuckDBãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹
            
            ### ğŸš€ ä½¿ç”¨æ–¹æ³•
            ```python
            import joblib
            import duckdb
            
            # ãƒ¢ãƒ‡ãƒ«ã¨å‰å‡¦ç†å™¨ã‚’èª­ã¿è¾¼ã¿
            model = joblib.load('house_price_prediction.pkl')
            preprocessor = joblib.load('house_price_prediction_encoders.pkl')
            
            # DuckDBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            conn = duckdb.connect('house_price_dwh.duckdb')
            data = conn.execute('SELECT * FROM v_house_analytics').fetchdf()
            conn.close()
            
            # äºˆæ¸¬å®Ÿè¡Œ
            # (DuckDBãƒ‡ãƒ¼ã‚¿ã§å‰å‡¦ç† â†’ äºˆæ¸¬)
            ```
            
            ### ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±
            - ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : Random Forest
            - ç‰¹å¾´é‡: sqft, bedrooms, bathrooms, house_age, price_per_sqft, bed_bath_ratio, location, condition
            - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: house price
            - ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: DuckDB DWH (v_house_analytics view)
            
            ### ğŸ”„ CI/CD
            ã“ã®ãƒªãƒªãƒ¼ã‚¹ã¯è‡ªå‹•CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚
            DuckDBãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹æ§‹ç¯‰ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¾ã§è‡ªå‹•åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 